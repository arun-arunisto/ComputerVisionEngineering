                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 1.2295,                0.77026,                      1,                 1.1348,             0.00023465,             0.00023465,             0.00023465
                      2,                0.64774,                0.92876,                      1,                 0.8891,             0.00044925,             0.00044925,             0.00044925
                      3,                 0.3919,                 0.9724,                      1,                0.80609,             0.00064029,             0.00064029,             0.00064029
                      4,                0.32355,                0.97863,                      1,                0.78802,             0.00060797,             0.00060797,             0.00060797
                      5,                0.24275,                0.98397,                      1,                0.78133,             0.00060797,             0.00060797,             0.00060797
                      6,                0.25175,                0.98397,                      1,                0.77715,             0.00057263,             0.00057263,             0.00057263
                      7,                0.20907,                0.98308,                      1,                0.76997,             0.00053728,             0.00053728,             0.00053728
                      8,                0.24204,                0.98842,                      1,                 0.7672,             0.00050194,             0.00050194,             0.00050194
                      9,                0.19261,                 0.9911,                      1,                0.76474,              0.0004666,              0.0004666,              0.0004666
                     10,                0.17506,                0.98575,                      1,                0.76711,             0.00043126,             0.00043126,             0.00043126
                     11,                 0.1637,                0.99199,                      1,                 0.7622,             0.00039591,             0.00039591,             0.00039591
                     12,                0.16136,                0.99288,                      1,                0.75958,             0.00036057,             0.00036057,             0.00036057
                     13,                0.17001,                0.99466,                      1,                0.75703,             0.00032523,             0.00032523,             0.00032523
                     14,                0.15251,                 0.9911,                      1,                0.76031,             0.00028988,             0.00028988,             0.00028988
                     15,                0.13302,                0.99466,                      1,                0.75768,             0.00025454,             0.00025454,             0.00025454
                     16,                 0.1798,                0.99644,                      1,                 0.7569,              0.0002192,              0.0002192,              0.0002192
                     17,                0.13063,                0.99466,                      1,                0.75703,             0.00018385,             0.00018385,             0.00018385
                     18,                0.13646,                0.99377,                      1,                 0.7562,             0.00014851,             0.00014851,             0.00014851
                     19,                0.12173,                 0.9911,                      1,                0.75723,             0.00011317,             0.00011317,             0.00011317
                     20,                0.13534,                0.99466,                      1,                0.75505,             7.7826e-05,             7.7826e-05,             7.7826e-05
